{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Tugas 4 Teknologi Perekayasaan Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```\n",
    "Nama  : nubisub\n",
    "NIM   : nim\n",
    "Kelas : 3SIIIIIIIIIIIIIIIIIIIIIUUUUUUUUUUUUUUUUUU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.Lakukan web scraping menggunakan Requests + BeautifulSoup untuk mengekstrak Tabel Matching Cryptocurrencies pada [tab Results List di Yahoo!Finance](  https://finance.yahoo.com/crypto/)  (cukup halaman pertama saja - 25 rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 1: Import library yang dibutuhkan dan Pengaturannya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import selenium.webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "chromedriver_path = 'chromedriver.exe'\n",
    "options = selenium.webdriver.ChromeOptions()\n",
    "options.headless =True\n",
    "driver = selenium.webdriver.Chrome(executable_path=chromedriver_path,options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 2: Membuka halaman web yang akan di scraping dan mengekstrak data yang dibutuhkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "driver.get(\"https://finance.yahoo.com/crypto/\")\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "table = soup.select('#scr-res-table > div.Ovx\\(a\\).Ovx\\(h\\)--print.Ovy\\(h\\).W\\(100\\%\\) > table')[0]\n",
    "data = []\n",
    "\n",
    "thead = table.select('thead')[0]\n",
    "tr = thead.select('tr')\n",
    "for i in tr:\n",
    "    th = i.select('th')\n",
    "    text = [j.text for j in th]\n",
    "    data.append(text)\n",
    "\n",
    "tbody = table.select('tbody')[0]\n",
    "tr = tbody.select('tr')\n",
    "for i in tr:\n",
    "    td = i.select('td')\n",
    "    text = [j.text for j in td]\n",
    "    data.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 3: Menyimpan data yang sudah di ekstrak ke dalam dataframe dan menampilkan hasilnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Symbol          Name Price (Intraday)   Change % Change Market Cap  \\\n",
      "0   BTC-USD   Bitcoin USD        23,751.09  +517.70   +2.23%   458.473B   \n",
      "1   ETH-USD  Ethereum USD         1,658.34   +53.83   +3.35%   202.937B   \n",
      "2  USDT-USD    Tether USD           1.0001  -0.0000   -0.00%    70.891B   \n",
      "3   BNB-USD       BNB USD           307.23    +3.58   +1.18%     48.51B   \n",
      "4  USDC-USD  USD Coin USD           1.0002  +0.0001   +0.01%    42.634B   \n",
      "\n",
      "0 Volume in Currency (Since 0:00 UTC) Volume in Currency (24Hr)  \\\n",
      "0                             19.553B                   19.553B   \n",
      "1                              6.751B                    6.751B   \n",
      "2                             27.474B                   27.474B   \n",
      "3                            381.712M                  381.712M   \n",
      "4                              2.917B                    2.917B   \n",
      "\n",
      "0 Total Volume All Currencies (24Hr) Circulating Supply 52 Week Range  \\\n",
      "0                            19.553B            19.303M                 \n",
      "1                             6.751B           122.374M                 \n",
      "2                            27.474B            70.884B                 \n",
      "3                           381.712M           157.896M                 \n",
      "4                             2.917B            42.627B                 \n",
      "\n",
      "0 Day Chart  \n",
      "0            \n",
      "1            \n",
      "2            \n",
      "3            \n",
      "4            \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(df.index[0])\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.head())\n",
    "df.to_csv('crypto.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.Lakukan web scraping menggunakan Scrapy untuk mengektrak salah satu tabel (silakan pilih sendiri) pada [halaman Champions League Stats di](https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 1: Import library yang dibutuhkan dan Pengaturannya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'scrapy_champion', using template directory 'C:\\Python311\\Lib\\site-packages\\scrapy\\templates\\project', created in:\n",
      "    C:\\Users\\Hendra Kusuma\\OneDrive - UGM 365\\Documents\\Semester 6\\1.Teknologi Perekayasaan Data\\Git\\meet4\\scrapy_champion\n",
      "\n",
      "You can start your first spider with:\n",
      "    cd scrapy_champion\n",
      "    scrapy genspider example example.com\n",
      "Created spider 'champion' using template 'basic' in module:\n",
      "  scrapy_champion.spiders.champion\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "import os\n",
    "import pandas as pd\n",
    "!scrapy startproject scrapy_champion\n",
    "os.chdir('scrapy_champion/scrapy_champion/spiders')\n",
    "!scrapy genspider champion https://www.footballdatabase.eu/id/kompetisi/secara_keseluruhan/16606-ligue_des_champions/2022-2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 2: Melakukan Scraping dan menyimpan hasilnya ke dalam csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:04:22 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scrapy_champion)\n",
      "2023-02-27 22:04:22 [scrapy.utils.log] INFO: Versions: lxml 4.9.2.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.1, Twisted 22.10.0, Python 3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)], pyOpenSSL 23.0.0 (OpenSSL 3.0.8 7 Feb 2023), cryptography 39.0.1, Platform Windows-10-10.0.22621-SP0\n",
      "2023-02-27 22:04:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'BOT_NAME': 'scrapy_champion',\n",
      " 'DOWNLOAD_DELAY': 3,\n",
      " 'FEED_EXPORT_ENCODING': 'utf-8',\n",
      " 'NEWSPIDER_MODULE': 'scrapy_champion.spiders',\n",
      " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
      " 'SPIDER_MODULES': ['scrapy_champion.spiders'],\n",
      " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
      "2023-02-27 22:04:22 [asyncio] DEBUG: Using selector: SelectSelector\n",
      "2023-02-27 22:04:22 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
      "2023-02-27 22:04:22 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop\n",
      "2023-02-27 22:04:22 [scrapy.extensions.telnet] INFO: Telnet Password: 157717e24091af8e\n",
      "2023-02-27 22:04:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2023-02-27 22:04:23 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2023-02-27 22:04:23 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2023-02-27 22:04:23 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2023-02-27 22:04:23 [scrapy.core.engine] INFO: Spider opened\n",
      "2023-02-27 22:04:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2023-02-27 22:04:23 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2023-02-27 22:04:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023> (referer: None)\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': None, 'Team': 'None', 'avgAge': None, 'oldestPlayerAge': None, 'youngestPlayerAge': None}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_4/4390.webp', 'Team': '', 'avgAge': '22.6', 'oldestPlayerAge': '(38 years)', 'youngestPlayerAge': '(17 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_0/487.webp', 'Team': 'Sturm Graz', 'avgAge': '23.1', 'oldestPlayerAge': '(31 years)', 'youngestPlayerAge': '(17 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_2/2425.webp', 'Team': 'Sutjeska Niksic', 'avgAge': '23.9', 'oldestPlayerAge': '(32 years)', 'youngestPlayerAge': '(17 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_0/367.webp', 'Team': 'Monaco', 'avgAge': '24', 'oldestPlayerAge': '(31 years)', 'youngestPlayerAge': '(18 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_0/450.webp', 'Team': 'Sporting CP', 'avgAge': '24.1', 'oldestPlayerAge': '(34 years)', 'youngestPlayerAge': '(16 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_2/2611.webp', 'Team': 'RU Saint-Gilles', 'avgAge': '24.2', 'oldestPlayerAge': '(31 years)', 'youngestPlayerAge': '(17 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_0/642.webp', 'Team': 'FC Copenhagen', 'avgAge': '24.2', 'oldestPlayerAge': '(33 years)', 'youngestPlayerAge': '(16 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_0/735.webp', 'Team': 'Maribor', 'avgAge': '24.3', 'oldestPlayerAge': '(35 years)', 'youngestPlayerAge': '(17 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_1/1135.webp', 'Team': 'Bodö/Glimt', 'avgAge': '24.5', 'oldestPlayerAge': '(31 years)', 'youngestPlayerAge': '(17 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_0/438.webp', 'Team': 'Bayer Leverkusen', 'avgAge': '24.5', 'oldestPlayerAge': '(32 years)', 'youngestPlayerAge': '(17 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_0/724.webp', 'Team': 'Club Brugge', 'avgAge': '24.5', 'oldestPlayerAge': '(33 years)', 'youngestPlayerAge': '(16 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_0/760.webp', 'Team': 'Shakhtar Donetsk', 'avgAge': '24.6', 'oldestPlayerAge': '(37 years)', 'youngestPlayerAge': '(18 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_1/1607.webp', 'Team': 'Midtjylland', 'avgAge': '24.6', 'oldestPlayerAge': '(36 years)', 'youngestPlayerAge': '(16 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_2/2200.webp', 'Team': 'Linfield', 'avgAge': '24.7', 'oldestPlayerAge': '(35 years)', 'youngestPlayerAge': '(16 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_0/590.webp', 'Team': '', 'avgAge': '24.7', 'oldestPlayerAge': '(33 years)', 'youngestPlayerAge': '(17 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_17/17478.webp', 'Team': 'Shkupi', 'avgAge': '24.8', 'oldestPlayerAge': '(33 years)', 'youngestPlayerAge': '(19 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_0/400.webp', 'Team': 'FC Barcelona', 'avgAge': '24.9', 'oldestPlayerAge': '(34 years)', 'youngestPlayerAge': '(17 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_0/413.webp', 'Team': 'PSV Eindhoven', 'avgAge': '24.9', 'oldestPlayerAge': '(37 years)', 'youngestPlayerAge': '(17 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_1/1131.webp', 'Team': 'Sheriff Tiraspol', 'avgAge': '24.9', 'oldestPlayerAge': '(39 years)', 'youngestPlayerAge': '(20 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.footballdatabase.eu/en/competition/overall/16606-ligue_des_champions/2022-2023>\n",
      "\n",
      "{'TeamLogo': '/images/photos/resampled/clubs/30/a_1/1020.webp', 'Team': 'KF Tirana', 'avgAge': '25', 'oldestPlayerAge': '(41 years)', 'youngestPlayerAge': '(16 years)'}\n",
      "2023-02-27 22:04:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2023-02-27 22:04:26 [scrapy.extensions.feedexport] INFO: Stored csv feed (21 items) in: TeamAgeStats.csv\n",
      "2023-02-27 22:04:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 281,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 46575,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 2.581682,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2023, 2, 27, 15, 4, 26, 104662),\n",
      " 'httpcompression/response_bytes': 339135,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 21,\n",
      " 'log_count/DEBUG': 25,\n",
      " 'log_count/INFO': 11,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2023, 2, 27, 15, 4, 23, 522980)}\n",
      "2023-02-27 22:04:26 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!scrapy crawl champion -o TeamAgeStats.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.Buat data scraping menggunakan API:\n",
    "    - Pilih salah satu penyedia data: Twitter/Instagram/Facebook/Google/atau lainnya\n",
    "    - Signup untuk mendapatkan akses autentikasi API\n",
    "    - Baca dan pelajari dokumentasi API-nya\n",
    "    - Ambil data dari penyedia data (cukup satu jenis data saja - 1 API method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 1: Import library yang dibutuhkan dan Pengaturannya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 2: Call API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_name': 'Mark', 'last_name': 'Zuckerberg', 'id': '4'}\n"
     ]
    }
   ],
   "source": [
    "url = 'https://graph.facebook.com/v16.0/4/?fields=about%2Cfirst_name%2Clast_name%2Cbirthday%2Cgender%2Clanguages&access_token=EAAwbeFuHIssBAOnRy892CzTZAFlbwwcoBCq7ZAsLS8hu2N7NKm35YMPzZAp2rkwqYVkGYQqXyGVDskXOdikZAlc65pc4FhVT6LKFePBk42M7pjrQfwzLAKzq0lV11yZAJa5uiIqZAFvbarlYGEPgMgQiZBCu1izxRK1hYz6PAxTU4qUQmqtUxPLJcjc3mWZB3uek5OpLvZAC6ZB1ozcrlesGNmeEZCXkGusyT3nVIG7lypm3WHmL3ZCoUgoJ'\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    # Extract JSON data dari response\n",
    "    data = response.json()\n",
    "    print(data)\n",
    "else:\n",
    "    print('Error')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 3: Menyimpan data yang sudah di ekstrak ke dalam dataframe dan menampilkan hasilnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  first_name   last_name id\n",
      "0       Mark  Zuckerberg  4\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data, index=[0])\n",
    "print(df.head())\n",
    "df.to_csv('facebook.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
